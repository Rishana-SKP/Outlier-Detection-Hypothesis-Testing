# Outlier Detection & Removal

Detecting and handling outliers is a crucial step in data preprocessing to ensure the quality and reliability of statistical analyses. Here are some notes on how to detect and remove outliers using various methods:

### Mean Function:
Detecting outliers using the mean function involves calculating the mean (average) of the data points and identifying values that significantly deviate from this mean.
Outliers can be defined as data points that lie beyond a certain number of standard deviations from the mean.
To remove outliers using the mean function, you can simply exclude data points that fall outside a predetermined range, such as those beyond ±3 standard deviations from the mean.

### Percentile Method:
The percentile method involves calculating percentiles, such as the 25th and 75th percentiles (also known as the first and third quartiles, respectively), and using them to define a range within which most of the data points lie.
Outliers can be identified as data points that fall below the lower percentile (e.g., 25th percentile - 1.5 * interquartile range) or above the higher percentile (e.g., 75th percentile + 1.5 * interquartile range).
Data points outside this range can be considered outliers and removed from the dataset.

### IQR (Interquartile Range) Method:
The Interquartile Range (IQR) method is closely related to the percentile method and is often used in conjunction with it.
The IQR is calculated as the difference between the third quartile (Q3) and the first quartile (Q1).
Outliers are identified as data points lying below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR.
Data points falling outside this range are considered outliers and can be removed.

### Normal Distribution:
Assuming the data follows a normal distribution, outliers can be detected using statistical measures such as z-scores.
A z-score measures how many standard deviations a data point is from the mean of the distribution.
Typically, data points with z-scores greater than a certain threshold (e.g., ±3) are considered outliers and can be removed from the dataset.

### Z-Score Method:
The z-score method is a specific application of the normal distribution approach.
To detect outliers using z-scores, calculate the z-score for each data point based on the mean and standard deviation of the dataset.
Data points with z-scores exceeding a predefined threshold (e.g., ±3) are considered outliers and can be removed.
In summary, these methods provide different approaches to detect and remove outliers from a dataset, and the choice of method depends on factors such as the distribution of the data and the specific requirements of the analysis.





# HYPOTHESIS TESTING
Hypothesis testing is a statistical method used to make inferences about population parameters based on sample data. Here are some key points about hypothesis testing:

### Formulating Hypotheses:
Hypothesis testing begins with the formulation of two hypotheses: the null hypothesis (H0) and the alternative hypothesis (H1 or Ha).
The null hypothesis typically represents the status quo or a default assumption about the population parameter, while the alternative hypothesis represents the claim or effect we are trying to test.

### Choosing a Test Statistic:
The choice of test statistic depends on the nature of the data and the hypothesis being tested.
Common test statistics include the z-score, t-statistic, chi-square statistic, and F-statistic, among others.

### Selecting the Significance Level:
The significance level (denoted by α) represents the probability of rejecting the null hypothesis when it is actually true.
Commonly used significance levels include 0.05, 0.01, and 0.10.

### Conducting the Test:
Based on the chosen test statistic and significance level, we calculate the probability of obtaining the observed sample results (or more extreme results) if the null hypothesis is true.
This probability is known as the p-value.

### Interpreting the Results:
If the p-value is less than or equal to the chosen significance level (α), we reject the null hypothesis in favor of the alternative hypothesis.
If the p-value is greater than the significance level, we fail to reject the null hypothesis. This does not necessarily mean that the null hypothesis is true; it simply means that there is not enough evidence to reject it based on the observed data.

